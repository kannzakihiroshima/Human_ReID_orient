{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1542f4f-4467-40cc-8ea5-5436f13a36cc",
   "metadata": {},
   "source": [
    "# 実験データの外観特徴量（OSNetから取得)と半教師体の向きラベル，体の向き特徴量(モデルAから取得)を結合する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb621ee-929d-47bf-b918-0957e300e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ファイルのパス\n",
    "file_path1 = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_origin.csv'\n",
    "file_path2 = 'C:/Users/sugie/PycharmProjects/pythonProject10/predicted_exp1_metric_front_back.csv'\n",
    "file_path3 = 'C:/Users/sugie/PycharmProjects/pythonProject10/predicted_exp2_metric_front_back.csv'\n",
    "file_path4 = 'C:/Users/sugie/PycharmProjects/pythonProject10/predicted_exp3_metric_front_back.csv'\n",
    "\n",
    "# データフレームを読み込む\n",
    "df1 = pd.read_csv(file_path1, dtype={'point_ID': str})\n",
    "df1_pre = pd.read_csv(file_path2, dtype={'point_ID': str})\n",
    "df2_pre = pd.read_csv(file_path3, dtype={'point_ID': str})\n",
    "df3_pre = pd.read_csv(file_path4, dtype={'point_ID': str})\n",
    "\n",
    "# df2を縦に結合 (predicted_labelを含む)\n",
    "df2 = pd.concat([df1_pre, df2_pre, df3_pre], axis=0)\n",
    "\n",
    "# df1に新しい列 'file_name_modified' を追加し、'_7' を除去したファイル名を格納\n",
    "df1['file_name_modified'] = df1['file_name'].str.replace('_7', '', regex=False)\n",
    "\n",
    "# df2も同様に 'file_name_modified' 列を作成\n",
    "df2['file_name_modified'] = df2['file_name']\n",
    "\n",
    "# 辞書型に変換 (predicted_1, predicted_2, predicted_3, predicted_labelをそれぞれの辞書に保存)\n",
    "df2_dict_predicted_1 = df2.set_index(['point_ID', 'file_name_modified', 'label'])['predicted_1'].to_dict()\n",
    "df2_dict_predicted_2 = df2.set_index(['point_ID', 'file_name_modified', 'label'])['predicted_2'].to_dict()\n",
    "df2_dict_predicted_3 = df2.set_index(['point_ID', 'file_name_modified', 'label'])['predicted_3'].to_dict()\n",
    "df2_dict_predicted_label = df2.set_index(['point_ID', 'file_name_modified', 'label'])['predicted_label'].to_dict()\n",
    "\n",
    "# df1にpredicted_1, predicted_2, predicted_3, predicted_labelを追加、対応するキーがない場合は空白\n",
    "df1['predicted_1'] = df1.apply(\n",
    "    lambda row: df2_dict_predicted_1.get((row['point_ID'], row['file_name_modified'], row['label']), ''), axis=1)\n",
    "df1['predicted_2'] = df1.apply(\n",
    "    lambda row: df2_dict_predicted_2.get((row['point_ID'], row['file_name_modified'], row['label']), ''), axis=1)\n",
    "df1['predicted_3'] = df1.apply(\n",
    "    lambda row: df2_dict_predicted_3.get((row['point_ID'], row['file_name_modified'], row['label']), ''), axis=1)\n",
    "df1['predicted_label'] = df1.apply(\n",
    "    lambda row: df2_dict_predicted_label.get((row['point_ID'], row['file_name_modified'], row['label']), ''), axis=1)\n",
    "\n",
    "# frontを0、backを1に変換\n",
    "df1['predicted_label'] = df1['predicted_label'].map({'front': 0, 'back': 1}).fillna('')  # frontを0、backを1に変換\n",
    "\n",
    "# 'predicted_1', 'predicted_2', 'predicted_3' のすべてが空白の行を削除\n",
    "df1 = df1[(df1['predicted_1'] != '') | (df1['predicted_2'] != '') | (df1['predicted_3'] != '')]\n",
    "\n",
    "# predicted_1, predicted_2, predicted_3をL2正規化\n",
    "def l2_normalize(row):\n",
    "    vector = np.array([row['predicted_1'], row['predicted_2'], row['predicted_3']], dtype=float)\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return row[['predicted_1', 'predicted_2', 'predicted_3']]  # すべて0の場合はそのまま返す\n",
    "    return vector / norm\n",
    "\n",
    "df1[['predicted_1', 'predicted_2', 'predicted_3']] = df1[['predicted_1', 'predicted_2', 'predicted_3']].apply(l2_normalize, axis=1, result_type='expand')\n",
    "\n",
    "# 結果を表示\n",
    "print(\"df1.head():\\n\", df1.head())\n",
    "\n",
    "# 結合したデータを新しいCSVファイルに保存\n",
    "output_file_path = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_front_back.csv'\n",
    "df1.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba11e79-d41a-4561-a141-4051bb0a5a23",
   "metadata": {},
   "source": [
    "# モデルBの学習のためにデータ前処理を行う\n",
    "### 撮影時間によって実験データを分割する\n",
    "撮影実験は3回，exp1-exp3\n",
    "\n",
    "３つの内，一つのexpをテストデータにするため，分割する．condition_strによって分割するexpを指定する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86167093-6e32-4920-afe8-4a82c5b85b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_and_filter_csv(input_file_path, output_file_with_condition, output_file_without_condition, chunk_size, condition_str):\n",
    "    \"\"\"\n",
    "    CSVファイルをチャンクに分割して読み込み、特定の条件でフィルタリングした後、結果を別のファイルに保存します。\n",
    "\n",
    "    :param input_file_path: 入力CSVファイルのパス\n",
    "    :param output_file_with_condition: 条件に一致する行を保存するファイルのパス\n",
    "    :param output_file_without_condition: 条件に一致しない行を保存するファイルのパス\n",
    "    :param chunk_size: チャンクサイズ\n",
    "    :param condition_str: フィルタリング条件の文字列\n",
    "    \"\"\"\n",
    "    for i, chunk in enumerate(pd.read_csv(input_file_path, chunksize=chunk_size)):\n",
    "        filtered_chunk_with_condition = chunk[chunk[\"file_name\"].str.contains(condition_str, na=False)]\n",
    "        filtered_chunk_without_condition = chunk[~chunk[\"file_name\"].str.contains(condition_str, na=False)]\n",
    "\n",
    "        if i == 0:\n",
    "            filtered_chunk_with_condition.to_csv(output_file_with_condition, index=False, mode='w', header=True)\n",
    "            filtered_chunk_without_condition.to_csv(output_file_without_condition, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            filtered_chunk_with_condition.to_csv(output_file_with_condition, index=False, mode='a', header=False)\n",
    "            filtered_chunk_without_condition.to_csv(output_file_without_condition, index=False, mode='a', header=False)\n",
    "\n",
    "##exp1,2とexp3を分解\n",
    "# 関数の使用例\n",
    "input_file_path = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_front_back.csv'\n",
    "output_file_with_exp3 = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_front_back_with_exp1.csv'\n",
    "output_file_without_exp3 = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_front_back_without_exp1.csv'\n",
    "chunk_size = 10000\n",
    "condition_str = 'exp1'\n",
    "\n",
    "split_and_filter_csv(input_file_path, output_file_with_exp3, output_file_without_exp3, chunk_size, condition_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07841e9e-c10c-4c4b-b4f7-312fb056fdf8",
   "metadata": {},
   "source": [
    "### 撮影地点で分割する\n",
    "\n",
    "６つの撮影地点の内，１つを訓練データとし，残りの５地点をテストデータとする\n",
    "\n",
    "point_conditionで訓練データを指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd979028-7c42-461c-a97b-66eb7b5f3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_and_filter_by_point(input_file_path, output_file_with_point, output_file_without_point, chunk_size, point_condition):\n",
    "    \"\"\"\n",
    "    CSVファイルをチャンクに分割して読み込み、指定された地点名が含まれているかどうかでデータを分割し、結果を別のファイルに保存します。\n",
    "\n",
    "    :param input_file_path: 入力CSVファイルのパス\n",
    "    :param output_file_with_point: 指定された地点名が含まれる行を保存するファイルのパス\n",
    "    :param output_file_without_point: 指定された地点名が含まれない行を保存するファイルのパス\n",
    "    :param chunk_size: チャンクサイズ\n",
    "    :param point_condition: フィルタリング条件として使用する地点名（例: 'point1'）\n",
    "    \"\"\"\n",
    "    for i, chunk in enumerate(pd.read_csv(input_file_path, chunksize=chunk_size)):\n",
    "        # 指定された地点名が含まれているかどうかでデータを分割\n",
    "        filtered_chunk_with_point = chunk[chunk[\"file_name\"].str.contains(point_condition, na=False)]\n",
    "        filtered_chunk_without_point = chunk[~chunk[\"file_name\"].str.contains(point_condition, na=False)]\n",
    "\n",
    "        # 結果をファイルに保存\n",
    "        if i == 0:\n",
    "            filtered_chunk_with_point.to_csv(output_file_with_point, index=False, mode='w', header=True)\n",
    "            filtered_chunk_without_point.to_csv(output_file_without_point, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            filtered_chunk_with_point.to_csv(output_file_with_point, index=False, mode='a', header=False)\n",
    "            filtered_chunk_without_point.to_csv(output_file_without_point, index=False, mode='a', header=False)\n",
    "\n",
    "# 関数の使用例\n",
    "input_file_path = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric.csv'\n",
    "output_file_with_point = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_with_point1.csv'\n",
    "output_file_without_point = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_without_point1.csv'\n",
    "chunk_size = 10000\n",
    "point_condition = 'point1'  # フィルタリング条件として使用する地点名\n",
    "\n",
    "split_and_filter_by_point(input_file_path, output_file_with_point, output_file_without_point, chunk_size, point_condition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
